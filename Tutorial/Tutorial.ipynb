{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL\n",
    "\n",
    "\n",
    "In this tutorial I will show how to run the second part of the notebook `Stocks_Performance_Predictor.ipyn`, which is also the most interesting one.\n",
    "\n",
    "I will use the files that have been uploaded in the Tutorial folder: those are the files that one would build in the first part of the notebook.\n",
    "\n",
    "We will also need the custom function `get_price_var()` at the end of this notebook (it comes from the main notebook).\n",
    "\n",
    "Let's begin from the required imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom function to pull prices of stocks\n",
    "def get_price_var(symbol):\n",
    "    '''\n",
    "    Get historical price data for a given symbol leveraging the power of pandas_datareader and Yahoo.\n",
    "    Compute the difference between first and last available time-steps in terms of Adjusted Close price.\n",
    "    \n",
    "    Input: ticker symbol\n",
    "    Output: percent price variation \n",
    "    '''\n",
    "    # read data\n",
    "    prices = data.DataReader(symbol, 'yahoo', '2019-01-01', '2019-12-31')['Adj Close']\n",
    "\n",
    "    # get all timestamps for specific lookups\n",
    "    today = prices.index[-1]\n",
    "    start = prices.index[0]\n",
    "\n",
    "    # calculate percentage price variation\n",
    "    price_var = ((prices[today] - prices[start]) / prices[start]) * 100\n",
    "    return price_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA\n",
    "\n",
    "It is now time to load the example data. The file `Example_Data.csv` contains all the financial data for the stocks from the Technology sector in the US stock exchange that are available from the Financial Modeling Prep API. The financial data are specified by the file `indicators.txt` (also available in this repo). The dataset has already been cleaned and prepared according to the following rules:\n",
    "\n",
    "  * remove all those columns that have more than 20 0-valued entries;\n",
    "  * remove all those columns that have more than 15 nan-valued entries;\n",
    "  * fill the remaining nan-valued entries with the average value of each column.\n",
    "  \n",
    "Those are the rules I followed, but their definition is up to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load complete dataset as pickle (dataframe with class column)\n",
    "df = pd.read_csv('Example_DATASET.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN TEST SPLIT\n",
    "\n",
    "Once the dataset is loaded, we must split it into training and testing. 20% of the data will be used to test the ML models, note the parameter `stratify` used in order to keep the same class-ratio between training and testing datasets.\n",
    "\n",
    "From the `train_split` and `test_split` we extract both input data `X_train`, `X_test` and output target data `y_train`, `y_test`.\n",
    "\n",
    "A sanity check is performed after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training samples: 510\n",
      "\n",
      "Number of testing samples: 128\n",
      "\n",
      "Number of features: 107\n"
     ]
    }
   ],
   "source": [
    "# Divide data in train and testing\n",
    "train_split, test_split = train_test_split(df, test_size=0.2, random_state=1, stratify=df['class'])\n",
    "X_train = train_split.iloc[:, :-1].values\n",
    "y_train = train_split.iloc[:, -1].values\n",
    "X_test = test_split.iloc[:, :-1].values\n",
    "y_test = test_split.iloc[:, -1].values\n",
    "\n",
    "print()\n",
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print()\n",
    "print(f'Number of testing samples: {X_test.shape[0]}')\n",
    "print()\n",
    "print(f'Number of features: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA STANDARDIZATION\n",
    "\n",
    "The next step consists in the standardization of the data. We leverage the `StandardScaler()` available from `scikit-learn`. It is important to use the same coefficients when standardizing both training and testing data: for this reason we first fit the scaler to `X_train`, and then apply it it both `X_train` and `X_test` via the method `.fit_transform()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize input data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML MODEL I: SUPPORT VECTOR MACHINE\n",
    "\n",
    "\n",
    "The first classification model we will run is the support vector machine. A `GridSeachCV` is performed in order to tune some hyper-parameters (`kernel`, `gamma`, `C`). The required number of cross-validations is set to 5. We want to achieve maximum weighted precision, in order to minimize the number of _false positives_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameters found on development set:\n",
      "\n",
      "0.713 for {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to be tuned\n",
    "tuned_parameters = [{'kernel': ['rbf', 'linear'],\n",
    "                     'gamma': [1e-3, 1e-4],\n",
    "                     'C': [0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "clf1 = GridSearchCV(SVC(random_state=1),\n",
    "                    tuned_parameters,\n",
    "                    n_jobs=6,\n",
    "                    scoring='precision_weighted',\n",
    "                    cv=5)\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "print('Best score and parameters found on development set:')\n",
    "print()\n",
    "print('%0.3f for %r' % (clf1.best_score_, clf1.best_params_))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML MODEL II: RANDOM FOREST\n",
    "\n",
    "\n",
    "The second classification model we will run is the random forest. A `GridSeachCV` is performed in order to tune some hyper-parameters (`n_estimators`, `max_features`, `max_depth`, `criterion`). The required number of cross-validations is set to 5. We want to achieve maximum weighted precision, in order to minimize the number of _false positives_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameters found on development set:\n",
      "\n",
      "0.724 for {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 32}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to be tuned\n",
    "tuned_parameters = {'n_estimators': [32, 256, 512, 1024],\n",
    "                    'max_features': ['auto', 'sqrt'],\n",
    "                    'max_depth': [4, 5, 6, 7, 8],\n",
    "                    'criterion': ['gini', 'entropy']}\n",
    "\n",
    "clf2 = GridSearchCV(RandomForestClassifier(random_state=1),\n",
    "                    tuned_parameters,\n",
    "                    n_jobs=6,\n",
    "                    scoring='precision_weighted',\n",
    "                    cv=5)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "print('Best score and parameters found on development set:')\n",
    "print()\n",
    "print('%0.3f for %r' % (clf2.best_score_, clf2.best_params_))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML MODEL III: EXTREME GRADIENT BOOSTING\n",
    "\n",
    "\n",
    "The third classification model we will run is the extreme gradient boosting. A `GridSeachCV` is performed in order to tune some hyper-parameters (`learning_rate`, `max_depth`, `n_estimators`). The required number of cross-validations is set to 5. We want to achieve maximum weighted precision, in order to minimize the number of _false positives_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameters found on development set:\n",
      "\n",
      "0.697 for {'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 256}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to be tuned\n",
    "tuned_parameters = {'learning_rate': [0.01, 0.001],\n",
    "                    'max_depth': [4, 5, 6, 7, 8],\n",
    "                    'n_estimators': [32, 128, 256]}\n",
    "\n",
    "clf3 = GridSearchCV(xgb.XGBClassifier(random_state=1),\n",
    "                   tuned_parameters,\n",
    "                   n_jobs=6,\n",
    "                   scoring='precision_weighted', \n",
    "                   cv=5)\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "print('Best score and parameters found on development set:')\n",
    "print()\n",
    "print('%0.3f for %r' % (clf3.best_score_, clf3.best_params_))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML MODEL IV: MULTI-LAYER PERCEPTRON\n",
    "\n",
    "\n",
    "The fourth classification model we will run is the multi-layer perceptron (feed-forward neural network). A `GridSeachCV` is performed in order to tune some hyper-parameters (`hidden_layer_sizes`, `activation`, `solver`). The required number of cross-validations is set to 5. We want to achieve maximum weighted precision, in order to minimize the number of _false positives_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score, and parameters, found on development set:\n",
      "\n",
      "0.730 for {'activation': 'relu', 'hidden_layer_sizes': (32, 64, 32), 'solver': 'adam'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to be tuned\n",
    "tuned_parameters = {'hidden_layer_sizes': [(32,), (64,), (32, 64, 32)],\n",
    "                    'activation': ['tanh', 'relu'],\n",
    "                    'solver': ['lbfgs', 'adam']}\n",
    "\n",
    "clf4 = GridSearchCV(MLPClassifier(random_state=1, batch_size=4, early_stopping=True), \n",
    "                    tuned_parameters,\n",
    "                    n_jobs=6,\n",
    "                    scoring='precision_weighted',\n",
    "                    cv=5)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print('Best score, and parameters, found on development set:')\n",
    "print()\n",
    "print('%0.3f for %r' % (clf4.best_score_, clf4.best_params_))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATE THE MODELS\n",
    "\n",
    "\n",
    "Now that 4 classification models have been trained, we must test them and compare their performance with respect to each other and to the benchmarks (S&P 500, DOW JONES). Indeed, we don't limit ourserlves to the comparison of their testing accuracies: we want to understand which model allows to make more money.\n",
    "\n",
    "First, we load the 2019 percent price variations for all the stocks, and we filter them in order to get only those used to test the models (`pvar_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all 2019 price variations for the tech stocks.\n",
    "pvar = pd.read_csv('Example_2019_price_var.csv', index_col=0)\n",
    "\n",
    "# Get 2019 price variations ONLY for the stocks in testing split\n",
    "pvar_test = pvar.loc[test_split.index.values, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build a new dataframe `df1` in which, for each tested stock, we collect all the predicted classes from each model (it is reminded that the two classes are `0`=IGNORE, `1`=BUY).\n",
    "\n",
    "If the model predicts class `1`, we proceed to buy 100 USD worth of that stock; otherwise, we ignore the stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial investment can be $100 for each stock whose predicted class = 1\n",
    "buy_amount = 100\n",
    "\n",
    "# In new dataframe df1, store all the information regarding each model's predicted class and relative gain/loss in $USD\n",
    "df1 = pd.DataFrame(y_test, index=test_split.index.values, columns=['ACTUAL']) # first column is the true class (BUY/INGORE)\n",
    "\n",
    "df1['SVM'] = clf1.predict(X_test) # predict class for testing dataset\n",
    "df1['VALUE START SVM [$]'] = df1['SVM'] * buy_amount # if class = 1 --> buy $100 of that stock\n",
    "df1['VAR SVM [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START SVM [$]'] # compute price variation in $\n",
    "df1['VALUE END SVM [$]'] = df1['VALUE START SVM [$]'] + df1['VAR SVM [$]'] # compute final value\n",
    "\n",
    "df1['RF'] = clf2.predict(X_test)\n",
    "df1['VALUE START RF [$]'] = df1['RF'] * buy_amount\n",
    "df1['VAR RF [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START RF [$]']\n",
    "df1['VALUE END RF [$]'] = df1['VALUE START RF [$]'] + df1['VAR RF [$]']\n",
    "\n",
    "df1['XGB'] = clf3.predict(X_test)\n",
    "df1['VALUE START XGB [$]'] = df1['XGB'] * buy_amount\n",
    "df1['VAR XGB [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START XGB [$]']\n",
    "df1['VALUE END XGB [$]'] = df1['VALUE START XGB [$]'] + df1['VAR XGB [$]']\n",
    "\n",
    "df1['MLP'] = clf4.predict(X_test)\n",
    "df1['VALUE START MLP [$]'] = df1['MLP'] * buy_amount\n",
    "df1['VAR MLP [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START MLP [$]']\n",
    "df1['VALUE END MLP [$]'] = df1['VALUE START MLP [$]'] + df1['VAR MLP [$]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we build a compact dataframe `MODELS_COMPARISON` in which we collect the main information required to perform the comparison between the classification models and the benchmarks (S&P 500, DOW JONES).\n",
    "\n",
    "Leveraging the dataframe `df1`, we can easily compute gains and losses for each model (`net_gain_`, `percent_gain_`).\n",
    "\n",
    "Since we miss the data from the benchmarks, we quickly exploit the custom function `get_price_var` in order to get the percent price variation for both S&P 500 (^GSPC) and DOW JONES (^DJI) for the year 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>RF</th>\n",
       "      <th>XGB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "      <th>DOW JONES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>INITIAL COST [USD]</th>\n",
       "      <td>12300.000000</td>\n",
       "      <td>4700.000000</td>\n",
       "      <td>10100.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FINAL VALUE [USD]</th>\n",
       "      <td>15701.241963</td>\n",
       "      <td>6624.897080</td>\n",
       "      <td>13268.852673</td>\n",
       "      <td>12834.504406</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[USD] GAIN/LOSS</th>\n",
       "      <td>3401.241963</td>\n",
       "      <td>1924.897080</td>\n",
       "      <td>3168.852673</td>\n",
       "      <td>2834.504406</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROI</th>\n",
       "      <td>27.652374</td>\n",
       "      <td>40.955257</td>\n",
       "      <td>31.374779</td>\n",
       "      <td>28.345044</td>\n",
       "      <td>28.7148</td>\n",
       "      <td>22.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SVM           RF           XGB           MLP  \\\n",
       "INITIAL COST [USD]  12300.000000  4700.000000  10100.000000  10000.000000   \n",
       "FINAL VALUE [USD]   15701.241963  6624.897080  13268.852673  12834.504406   \n",
       "[USD] GAIN/LOSS      3401.241963  1924.897080   3168.852673   2834.504406   \n",
       "ROI                    27.652374    40.955257     31.374779     28.345044   \n",
       "\n",
       "                    S&P 500 DOW JONES  \n",
       "INITIAL COST [USD]                     \n",
       "FINAL VALUE [USD]                      \n",
       "[USD] GAIN/LOSS                        \n",
       "ROI                 28.7148     22.24  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new, compact, dataframe in order to show gain/loss for each model\n",
    "start_value_svm = df1['VALUE START SVM [$]'].sum()\n",
    "final_value_svm = df1['VALUE END SVM [$]'].sum()\n",
    "net_gain_svm = final_value_svm - start_value_svm\n",
    "percent_gain_svm = (net_gain_svm / start_value_svm) * 100\n",
    "\n",
    "start_value_rf = df1['VALUE START RF [$]'].sum()\n",
    "final_value_rf = df1['VALUE END RF [$]'].sum()\n",
    "net_gain_rf = final_value_rf - start_value_rf\n",
    "percent_gain_rf = (net_gain_rf / start_value_rf) * 100\n",
    "\n",
    "start_value_xgb = df1['VALUE START XGB [$]'].sum()\n",
    "final_value_xgb = df1['VALUE END XGB [$]'].sum()\n",
    "net_gain_xgb = final_value_xgb - start_value_xgb\n",
    "percent_gain_xgb = (net_gain_xgb / start_value_xgb) * 100\n",
    "\n",
    "start_value_mlp = df1['VALUE START MLP [$]'].sum()\n",
    "final_value_mlp = df1['VALUE END MLP [$]'].sum()\n",
    "net_gain_mlp = final_value_mlp - start_value_mlp\n",
    "percent_gain_mlp = (net_gain_mlp / start_value_mlp) * 100\n",
    "\n",
    "percent_gain_sp500 = get_price_var('^GSPC') # get percent gain of S&P500 index\n",
    "percent_gain_dj = get_price_var('^DJI') # get percent gain of DOW JONES index\n",
    "\n",
    "MODELS_COMPARISON = pd.DataFrame([start_value_svm, final_value_svm, net_gain_svm, percent_gain_svm],\n",
    "                    index=['INITIAL COST [USD]', 'FINAL VALUE [USD]', '[USD] GAIN/LOSS', 'ROI'], columns=['SVM'])\n",
    "MODELS_COMPARISON['RF'] = [start_value_rf, final_value_rf, net_gain_rf, percent_gain_rf]\n",
    "MODELS_COMPARISON['XGB'] = [start_value_xgb, final_value_xgb, net_gain_xgb, percent_gain_xgb]\n",
    "MODELS_COMPARISON['MLP'] = [start_value_mlp, final_value_mlp, net_gain_mlp, percent_gain_mlp]\n",
    "MODELS_COMPARISON['S&P 500'] = ['', '', '', percent_gain_sp500]\n",
    "MODELS_COMPARISON['DOW JONES'] = ['', '', '', percent_gain_dj]\n",
    "MODELS_COMPARISON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataframe `MODELS_COMPARISON`, it is possible to see that:\n",
    "\n",
    "  * XGB and RF are the ML models that yield the highest ROI, 31.3% and 40.9% respectively\n",
    "  * RF outperforms the S&P 500 by more than 12 p.p, while it outperforms the DOW JONES by almost 20 p.p.\n",
    "  * XGB outperforms the S&P 500 by a few p.p., while it outperforms the DOW JONES by almost 10 p.p.\n",
    "  * MLP and SVM are closely matched, and yield an ROI of 28.3% and 27.2% respectively\n",
    "  * MLP and SVM perform similarly to the S&P 500, while they both outperfom the DOW JONES\n",
    "  * the SVM leads to the highest net gains, at about 3290 USD; however, it also has the highest initial investment cost at 12100 USD\n",
    "  * the RF leads to the lowest net gains, at about 1920 USD; however, it also has the lowest initial investment cost at 4700 USD\n",
    "\n",
    "So, this example proves, at least as proof-of-concept, that it is possible to find useful information in the 10-K filings that the publicly traded companies release. The financial information can be used to train machine learning models that learn to recognize buy-worthy stocks.\n",
    "\n",
    "\n",
    "For what concerns a more traditional comparison between the performance of the ML models implemented, it is possible to analyze the `classification_report`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================\n",
      "               SUPPORT VECTOR MACHINE\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IGNORE       0.40      0.05      0.09        38\n",
      "         BUY       0.71      0.97      0.82        90\n",
      "\n",
      "    accuracy                           0.70       128\n",
      "   macro avg       0.55      0.51      0.45       128\n",
      "weighted avg       0.62      0.70      0.60       128\n",
      "\n",
      "-----------------------------------------------------\n",
      "=====================================================\n",
      "                    RANDOM FOREST\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IGNORE       0.37      0.79      0.50        38\n",
      "         BUY       0.83      0.43      0.57        90\n",
      "\n",
      "    accuracy                           0.54       128\n",
      "   macro avg       0.60      0.61      0.54       128\n",
      "weighted avg       0.69      0.54      0.55       128\n",
      "\n",
      "-----------------------------------------------------\n",
      "=====================================================\n",
      "              EXTREME GRADIENT BOOSTING\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IGNORE       0.48      0.34      0.40        38\n",
      "         BUY       0.75      0.84      0.80        90\n",
      "\n",
      "    accuracy                           0.70       128\n",
      "   macro avg       0.62      0.59      0.60       128\n",
      "weighted avg       0.67      0.70      0.68       128\n",
      "\n",
      "-----------------------------------------------------\n",
      "=====================================================\n",
      "               MULTI-LAYER PERCEPTRON\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IGNORE       0.39      0.29      0.33        38\n",
      "         BUY       0.73      0.81      0.77        90\n",
      "\n",
      "    accuracy                           0.66       128\n",
      "   macro avg       0.56      0.55      0.55       128\n",
      "weighted avg       0.63      0.66      0.64       128\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print()\n",
    "print(53 * '=')\n",
    "print(15 * ' ' + 'SUPPORT VECTOR MACHINE')\n",
    "print(53 * '-')\n",
    "print(classification_report(y_test, clf1.predict(X_test), target_names=['IGNORE', 'BUY']))\n",
    "print(53 * '-')\n",
    "print(53 * '=')\n",
    "print(20 * ' ' + 'RANDOM FOREST')\n",
    "print(53 * '-')\n",
    "print(classification_report(y_test, clf2.predict(X_test), target_names=['IGNORE', 'BUY']))\n",
    "print(53 * '-')\n",
    "print(53 * '=')\n",
    "print(14 * ' ' + 'EXTREME GRADIENT BOOSTING')\n",
    "print(53 * '-')\n",
    "print(classification_report(y_test, clf3.predict(X_test), target_names=['IGNORE', 'BUY']))\n",
    "print(53 * '-')\n",
    "print(53 * '=')\n",
    "print(15 * ' ' + 'MULTI-LAYER PERCEPTRON')\n",
    "print(53 * '-')\n",
    "print(classification_report(y_test, clf4.predict(X_test), target_names=['IGNORE', 'BUY']))\n",
    "print(53 * '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking carefully, it is fair to ask: **why does the RF returns the highest ROI if it is the method with the lowest weighted accuracy?** This happens because:\n",
    "\n",
    "  * RF has the highest precision for the BUY class (83%). Indeed, 83% of the BUY predictions are _true positives_, and the remaning 17% are _false positives_\n",
    "  * Mimizing the number of _false positives_ allows to minimize the quantity of money spent on stocks that will decrease in value during 2019\n",
    "  * RF has the highest recall for the IGNORE class (79%), meaning that it correctly identified 79% of the stocks that should not be bought\n",
    "\n",
    "However, all this means that we miss a lot of potential stocks to be bought, since RF leads to a high number of _false negatives_. Indeed, it is easy to see that RF has the lowest recall value for the BUY class (43%), meaning that we only find 43% of the total stocks that should have been classified as BUY-worthy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('FinPro': conda)",
   "language": "python",
   "name": "python37564bitfinprocondaa9ae4c24bd38409e9c51635336a4cf81"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
